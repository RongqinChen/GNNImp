{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"datasets/p19/rawdata/training_setA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
      "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
      "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
      "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
      "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
      "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
      "       'HospAdmTime', 'ICULOS', 'SepsisLabel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fpath = \"../datasets/p19/rawdata/training_setA/p000001.psv\"\n",
    "\n",
    "data = pd.read_csv(fpath, sep=\"|\", header=0)\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
      "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
      "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
      "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
      "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
      "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
      "       'HospAdmTime', 'ICULOS', 'SepsisLabel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fpath = \"../datasets/p19/rawdata/training_setB/p100001.psv\"\n",
    "\n",
    "data = pd.read_csv(fpath, sep=\"|\", header=0)\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 4\n"
     ]
    }
   ],
   "source": [
    "temp_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'BaseExcess', 'HCO3',\n",
    "    'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos', 'Calcium',\n",
    "    'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate',\n",
    "    'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct',\n",
    "    'Hgb', 'PTT', 'WBC', 'Fibrinogen', 'Platelets']\n",
    "\n",
    "static_columns = ['Age', 'Gender', 'Unit1', 'Unit2']\n",
    "\n",
    "sepsis_column = 'SepsisLabel'\n",
    "\n",
    "time_column = 'ICULOS'\n",
    "\n",
    "print(len(temp_columns), len(static_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 34)\n",
      "(54, 4)\n",
      "(54,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fpath = \"../datasets/p19/rawdata/training_setA/p000001.psv\"\n",
    "\n",
    "data = pd.read_csv(fpath, sep=\"|\", header=0)\n",
    "tempX = data[temp_columns]\n",
    "print(tempX.shape)\n",
    "staticX = data[static_columns]\n",
    "print(staticX.shape)\n",
    "sepsis = data[sepsis_column]\n",
    "print(sepsis.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20337 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20337/20337 [00:51<00:00, 392.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "PTdict_list = []\n",
    "outcome_list = []\n",
    "\n",
    "folderA = \"../datasets/p19/rawdata/training_setA/\"\n",
    "\n",
    "\n",
    "for fname in tqdm(os.listdir(folderA)):\n",
    "    if not fname.endswith('.psv'):\n",
    "        continue\n",
    "\n",
    "    fpath = f\"{folderA}/{fname}\"\n",
    "\n",
    "    data = pd.read_csv(fpath, sep=\"|\", header=0)\n",
    "    tempX = data[temp_columns].fillna(0).values\n",
    "    staticX = data[static_columns].fillna(0).values[0]\n",
    "    pid = int(fname[1:-4])\n",
    "    Tarr = data[time_column].fillna(0).values.reshape((-1, 1))\n",
    "    sepsis = data[sepsis_column].fillna(0).values\n",
    "\n",
    "    # y = 1 if np.any(sepsis) else 0\n",
    "    sepidx = -1\n",
    "    for idx in range(len(sepsis)-1, 0, -1):\n",
    "        if sepsis[idx] == 1:\n",
    "            sepidx = idx\n",
    "    \n",
    "    if sepidx == -1 and tempX.shape[0] > 60:\n",
    "        continue\n",
    "\n",
    "    if 0 <= sepidx < 12:\n",
    "        continue\n",
    "\n",
    "    y = 0\n",
    "    if sepidx >= 12:\n",
    "        onset, offset = max(0, sepidx-6-60), sepidx-6\n",
    "        tempX = tempX[onset:offset, :]\n",
    "        Tarr = Tarr[onset:offset, :]\n",
    "        y = 1\n",
    "\n",
    "    length = tempX.shape[0]\n",
    "    if length < 60:\n",
    "        tempX = np.concatenate((tempX, np.zeros((60-length, tempX.shape[1]))))\n",
    "        Tarr = np.concatenate((Tarr, np.zeros((60-length, Tarr.shape[1]))))\n",
    "\n",
    "    Pdict = {\n",
    "        'id': pid,\n",
    "        'extended_static': staticX,\n",
    "        'arr': tempX,\n",
    "        'time': Tarr,\n",
    "        # 'sepsis': sepsis,\n",
    "        'length': length\n",
    "    }\n",
    "    \n",
    "\n",
    "    PTdict_list.append(Pdict)\n",
    "    outcome_list.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [00:49<00:00, 407.73it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folderB = \"../datasets/p19/rawdata/training_setB/\"\n",
    "\n",
    "\n",
    "for fname in tqdm(os.listdir(folderB)):\n",
    "    if not fname.endswith('.psv'):\n",
    "        continue\n",
    "\n",
    "    fpath = f\"{folderB}/{fname}\"\n",
    "\n",
    "    data = pd.read_csv(fpath, sep=\"|\", header=0)\n",
    "    tempX = data[temp_columns].fillna(0).values\n",
    "    staticX = data[static_columns].fillna(0).values[0]\n",
    "    pid = int(fname[1:-4]) + 100000\n",
    "    Tarr = data[time_column].fillna(0).values.reshape((-1, 1))\n",
    "    sepsis = data[sepsis_column].fillna(0).values\n",
    "\n",
    "    # y = 1 if np.any(sepsis) else 0\n",
    "    sepidx = -1\n",
    "    for idx in range(len(sepsis)-1, 0, -1):\n",
    "        if sepsis[idx] == 1:\n",
    "            sepidx = idx\n",
    "    \n",
    "    if sepidx == -1 and tempX.shape[0] > 60:\n",
    "        continue\n",
    "\n",
    "    if 0 <= sepidx < 12:\n",
    "        continue\n",
    "\n",
    "    y = 0\n",
    "    if sepidx >= 12:\n",
    "        onset, offset = max(0, sepidx-6-60), sepidx-6\n",
    "        tempX = tempX[onset:offset, :]\n",
    "        Tarr = Tarr[onset:offset, :]\n",
    "        y = 1\n",
    "\n",
    "    length = tempX.shape[0]\n",
    "    if length < 60:\n",
    "        tempX = np.concatenate((tempX, np.zeros((60-length, tempX.shape[1]))))\n",
    "        Tarr = np.concatenate((Tarr, np.zeros((60-length, Tarr.shape[1]))))\n",
    "\n",
    "    Pdict = {\n",
    "        'id': pid,\n",
    "        'extended_static': staticX,\n",
    "        'arr': tempX,\n",
    "        'time': Tarr,\n",
    "        # 'sepsis': sepsis,\n",
    "        'length': length\n",
    "    }\n",
    "    \n",
    "\n",
    "    PTdict_list.append(Pdict)\n",
    "    outcome_list.append(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39119 39119 0.04956670671540683\n"
     ]
    }
   ],
   "source": [
    "print(len(PTdict_list), len(outcome_list), sum(outcome_list) / len(outcome_list))\n",
    "np.save('../datasets/p19/processed_data/PTdict_list.npy', PTdict_list)\n",
    "np.save('../datasets/p19/processed_data/arr_outcomes.npy', outcome_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1939"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(outcome_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed0_split0 31295 3912 3912\n",
      "seed0_split1 31295 3912 3912\n",
      "seed0_split2 31295 3912 3912\n",
      "seed0_split3 31295 3912 3912\n",
      "seed0_split4 31295 3912 3912\n",
      "seed1_split0 31295 3912 3912\n",
      "seed1_split1 31295 3912 3912\n",
      "seed1_split2 31295 3912 3912\n",
      "seed1_split3 31295 3912 3912\n",
      "seed1_split4 31295 3912 3912\n",
      "seed2_split0 31295 3912 3912\n",
      "seed2_split1 31295 3912 3912\n",
      "seed2_split2 31295 3912 3912\n",
      "seed2_split3 31295 3912 3912\n",
      "seed2_split4 31295 3912 3912\n",
      "seed3_split0 31295 3912 3912\n",
      "seed3_split1 31295 3912 3912\n",
      "seed3_split2 31295 3912 3912\n",
      "seed3_split3 31295 3912 3912\n",
      "seed3_split4 31295 3912 3912\n",
      "seed4_split0 31295 3912 3912\n",
      "seed4_split1 31295 3912 3912\n",
      "seed4_split2 31295 3912 3912\n",
      "seed4_split3 31295 3912 3912\n",
      "seed4_split4 31295 3912 3912\n",
      "seed5_split0 31295 3912 3912\n",
      "seed5_split1 31295 3912 3912\n",
      "seed5_split2 31295 3912 3912\n",
      "seed5_split3 31295 3912 3912\n",
      "seed5_split4 31295 3912 3912\n",
      "seed6_split0 31295 3912 3912\n",
      "seed6_split1 31295 3912 3912\n",
      "seed6_split2 31295 3912 3912\n",
      "seed6_split3 31295 3912 3912\n",
      "seed6_split4 31295 3912 3912\n",
      "seed7_split0 31295 3912 3912\n",
      "seed7_split1 31295 3912 3912\n",
      "seed7_split2 31295 3912 3912\n",
      "seed7_split3 31295 3912 3912\n",
      "seed7_split4 31295 3912 3912\n",
      "seed8_split0 31295 3912 3912\n",
      "seed8_split1 31295 3912 3912\n",
      "seed8_split2 31295 3912 3912\n",
      "seed8_split3 31295 3912 3912\n",
      "seed8_split4 31295 3912 3912\n",
      "seed9_split0 31295 3912 3912\n",
      "seed9_split1 31295 3912 3912\n",
      "seed9_split2 31295 3912 3912\n",
      "seed9_split3 31295 3912 3912\n",
      "seed9_split4 31295 3912 3912\n",
      "split IDs saved\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "from torch_geometric.seed import seed_everything\n",
    "\n",
    "\n",
    "\"\"\"Use 8:1:1 split\"\"\"\n",
    "p_train = 0.80\n",
    "p_val = 0.10\n",
    "p_test = 0.10\n",
    "\n",
    "os.makedirs(\"../datasets/p19/splits\", exist_ok=True)\n",
    "\n",
    "n = len(PTdict_list)  # original 12000 patients, remove 12 outliers\n",
    "n_train = round(n*p_train)\n",
    "n_val = round(n*p_val)\n",
    "n_test = n - (n_train+n_val)\n",
    "Nsplits = 5\n",
    "\n",
    "for seed in range(10):\n",
    "    seed_everything(seed)\n",
    "    for split in range(Nsplits):\n",
    "        p = np.random.permutation(n)\n",
    "        idx_train = p[:n_train]\n",
    "        idx_val = p[n_train:n_train+n_val]\n",
    "        idx_test = p[n_train+n_val:]\n",
    "        with open(f'../datasets/p19/splits/seed{seed}_split{split}.pkl', 'wb') as wbfile:\n",
    "            print(f'seed{seed}_split{split}', len(idx_train), len(idx_val), len(idx_test))\n",
    "            pkl.dump((idx_train, idx_val, idx_test), wbfile)\n",
    "\n",
    "print('split IDs saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n"
     ]
    }
   ],
   "source": [
    "PTdict_list = np.load('../datasets/p19/processed_data/PTdict_list.npy', allow_pickle=True)\n",
    "\n",
    "length_list = [\n",
    "    PTdict['arr'].shape[0]\n",
    "    for PTdict in PTdict_list\n",
    "]\n",
    "print(max(length_list), min(length_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
